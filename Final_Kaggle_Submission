{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99928,"databundleVersionId":12027201,"sourceType":"competition"},{"sourceId":12054218,"sourceType":"datasetVersion","datasetId":7586361}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### __Group Assignment - Predicting Airbnb Listing Prices in Melbourne, Australia__","metadata":{}},{"cell_type":"markdown","source":"--- \n\n**Kaggle Competition Ends:** Friday, 6 June 2025 @ 3:00pm (Week 13)  \n**Assignment Due Date on iLearn:** Friday, 6 June 2025 @ 11.55pm (Week 13)   \n**Total Marks:** 30\n\n**Overview:**   \n\n- In the group assignment you will form a team of 3 students and participate in a forecasting competition on Kaggle\n","metadata":{}},{"cell_type":"markdown","source":"**Instructions:** \n\n- Form a team of 3 students \n- Each team member needs to join [https://www.kaggle.com](https://www.kaggle.com/)  \n- Choose a team leader and form a team on Kaggle [https://www.kaggle.com/t/fc5974a56165cea945ee1ec182b079af](https://www.kaggle.com/t/fc5974a56165cea945ee1ec182b079af)\n    - Team leader to click on `team` and invite other 2 team members to join\n    - Your **team's name must start** with our unit code\n- All team members should work on all the tasks however   \n    - Each team member will be responsible for one of the 3 tasks listed below    \n- **Your predictions must be generated by a model you develop here** \n    - You will receive a mark of **zero** if your code is not able produce the forecasts you submit to Kaggle ","metadata":{}},{"cell_type":"markdown","source":"**Competition Rankings**\n\nThe rankings for the competition are determined through two different leaderboards:\n\n- **Public Leaderboard Ranking**: Available during the competition, these rankings are calculated based on 50% of the test dataset, which includes 1,500 observations. This allows participants to see how they are performing while the competition is still ongoing.\n- **Final Leaderboard Ranking**: These rankings are recalculated from the other 50% of the test dataset, which consists of the remaining 1,500 observations, and are revealed 5 minutes after the competition concludes. This final evaluation determines the ultimate standings of the competition.\n\n\n\n**Marks** \n\n- Assignment: 30 marks consisting of Solutions (27 marks) + Video Presentation (3 marks)\n- **Each Student's Mark: 50% x overall assignment mark + 50% x mark for the task that you are responsible for**  \n","metadata":{}},{"cell_type":"markdown","source":"\n**Submissions:**  \n\n1. On Kaggle: submit your team's forecast in order to be ranked by Kaggle\n2. On iLearn **only team leader to submit** the assignment Jupyter notebook re-named to your team's name on Kaggle   \n    - The Jupyter notebook must contain team members names/ID numbers, and the group name Kaggle\n    - One 15 minute video recording of your work \n        - 5 marks will be deducted from each Task for which there is no video presentation   \n","metadata":{}},{"cell_type":"markdown","source":"---\n---","metadata":{}},{"cell_type":"markdown","source":"### >**Fill out the following information**\n\n- Team Name on Kaggle: `(COMP3020 Back Benchers)`\n- Team Leader and Team Member 1: `(Max Cochrane)`\n- Team Member 2: `(Rohini Maharaj)`\n- Team Member 3: `(Shambhav Shrestha)`","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Task 1: Problem Description and Initial Data Analysis\n\n- You must clearly explain all your answers in both the Markdown file and the recorded video.\n\n**Total Marks: 9**   \n\nBased on the Competition Overview, datasets and additional information provided on Kaggle, along with insights gained from personal research of the topic, write **Problem Description** (about 500 words) focusing on the sections listed below: \n1. Forecasting Problem - explain what we are trying to do and how it could be used in the real world, e.g. who and how may benefit from it (2 marks)    \n2. Evaluation Criteria - discuss the criterion that is used in this competition to assess forecasting performance, and its pros and cons. (2 marks)     \n3. Categorise all variables provided in the dataset according to their type; Hint: similar to what we had in Programming Task 1 (2 marks)  \n4. Missing Values - explain what you find for both the training and test datasets at this stage (2 marks)\n5. Provide and discuss some interesting *univariate* data characteristics (e.g. summary statistics and plots) in the training dataset  (1 marks)       \n- Hints:\n    - You should **not** discuss any specific predictive algorithms at this stage\n","metadata":{}},{"cell_type":"markdown","source":"Student in charge of this task: `(Rohini Maharaj)`","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.gridspec import GridSpec\nimport numpy as np\n\ntrain = pd.read_csv('/kaggle/input/competition-datasets/train.csv')\ntest = pd.read_csv('/kaggle/input/competition-datasets/test.csv')\nsolution = pd.read_csv('/kaggle/input/competition-datasets/sample-solution.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:16:57.900282Z","iopub.execute_input":"2025-06-04T06:16:57.900599Z","iopub.status.idle":"2025-06-04T06:16:58.355829Z","shell.execute_reply.started":"2025-06-04T06:16:57.900576Z","shell.execute_reply":"2025-06-04T06:16:58.354496Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. **Forecasting Problem**\nThe primary objective of this assignment is to accurately forecast the nightly prices of Airbnb listings based on the features provided in the new dataset. This forecasting capability is essential for delivering strategic business value across several segments of the short-term rental market. Precise price predictions can have significant implications in the following areas:\n\n**Host revenue optimisation**: \nHosts can use reliable price forecasts to avoid under-pricing (which would reduce their potential earnings) and over-pricing (which could deter prospective guests). By aligning their rates with anticipated demand and comparable listings, hosts maintain a competitive advantage and maximise occupancy.\n\n**Occupancy and yield management**:\nProperty managers and platform operators can leverage price forecasts to understand seasonal and local market trends. This insight enables informed decisions about when to adjust prices to smooth occupancy rates, thereby improving overall yield and reducing vacant nights.\n\n**Investment and portfolio planning**:\nInvestors and portfolio managers who hold multiple short-term rental properties can use forecasting to evaluate which neighbourhoods or property types are likely to yield higher returns. By anticipating price trends, they can make data-driven decisions about property acquisition, renovation budgets and targeted marketing campaigns.\n\nThese objectives align with the new dataset’s structure, which includes listing attributes such as location (neighbourhood), room type, number of bedrooms and bathrooms, amenities, host experience and other listing details. Your task is to preprocess the data, engineer relevant features, and develop one or more machine learning models that can predict the “price” column for unseen listings (i.e. the test set), ensuring that the predictions are as accurate as possible.","metadata":{}},{"cell_type":"markdown","source":"## **2. Evaluation Criteria**\n\nThe assignment uses Mean Absolute Percentage Error (MAPE) to assess forecasting performance. MAPE is advantageous due to its interpretability, expressing errors as percentages. It measures relative errors, allowing for fair comparisons across different nightly price ranges. For example, a model that forecasts budget listings and one that forecasts premium listings can be compared on the same scale, making it easier to identify which model performs better regardless of the price level. Furthermore, MAPE encourages robust model development because it is sensitive to outliers. Its widespread use across various industries highlights its adaptability and encourages participants to iteratively refine their models.","metadata":{}},{"cell_type":"markdown","source":"## **3. Categorising Values**\n |Variable Type|Number of Features|Feature Names| \n |---|---|---| \n |**Numeric** | 9 | price, latitude, longitude, accommodates, bedrooms, bathrooms, beds, number_of_reviews, review_scores_rating |\n | **Categorical** | 5 | room_type, property_type, neighbourhood, cancellation_policy, host_is_superhost |\n | **Boolean** | 3 | instant_bookable, host_has_profile_pic, host_identity_verified |\n | **Date/Time** | 4 | host_since, first_review, last_review, calendar_updated |\n | **Text** | 3 | name, description, neighbourhood_overview | \n \n <br> \n Five main variable types: Numeric (9 features), Categorical (5 features), Boolean (3 features), Date/Time (4 features) and Text (3 features)\nNumeric variables are numbers, categorical variables are non-ordered groups, boolean variables are True/False values, date/time variables record dates or times, and text variables contain free-form text.","metadata":{}},{"cell_type":"code","source":"#Data type identification\nprint(\"===============================================================\")\nprint(\"       Data-Type Identification for Training and Test Data Sets\") \nprint(\"===============================================================\")\n\nprint(\"---------------------------------------------------------------\")\nprint(\"Training Dataframe\")\nprint(\"---------------------------------------------------------------\")\nprint(train.dtypes)\n\nprint(\"---------------------------------------------------------------\")\nprint(\"Test Dataframe\")\nprint(\"---------------------------------------------------------------\")\nprint(test.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:06.471161Z","iopub.execute_input":"2025-06-04T06:15:06.471596Z","iopub.status.idle":"2025-06-04T06:15:06.481348Z","shell.execute_reply.started":"2025-06-04T06:15:06.471574Z","shell.execute_reply":"2025-06-04T06:15:06.480172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Data Type Findings**\n\n---\n\nThe dataset comprises approximately 50% categorical/text features, 35% numeric features and 15% date or boolean style features. Most object-type columns such as `source`, `name`, `description`, `neighborhood_overview`, `host_name`, `property_type`, `room_type` and `amenities` will need encoding or natural-language processing for any free-text fields. Date fields (for example, `host_since`, `first_review`, `last_review` and `calendar_updated`) must be converted into datetime format. Boolean-style features such as `instant_bookable`, `host_has_profile_pic` and `host_identity_verified` are currently stored as text and should be cast to binary values (0 or 1). Numeric columns such as `ID`, `host_listings_count`, `latitude`, `longitude`, `accommodates`, `bedrooms`, `beds`, `availability_30`, `number_of_reviews` and `review_scores_rating` can be used directly or scaled for modelling. Both the training and test sets share the same schema and data types so any preprocessing steps applied to one can be mirrored on the other without error.\n","metadata":{}},{"cell_type":"markdown","source":"## **4. Missing Values**","metadata":{}},{"cell_type":"code","source":"#Total Missing values for 'Test'and 'Train' datasets\nprint(\"===============================================================\")\nprint(\"        Missing Value Identification for both Datasets         \") \nprint(\"===============================================================\")\n\nprint(\"---------------------------------------------------------------\")\nprint(\"Train Dataframe\")\nprint(\"---------------------------------------------------------------\")\nprint(train.isnull().sum())\n\nprint(\"---------------------------------------------------------------\")\nprint(\"Test Dataframe\")\nprint(\"---------------------------------------------------------------\")\nprint(test.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:06.482281Z","iopub.execute_input":"2025-06-04T06:15:06.482572Z","iopub.status.idle":"2025-06-04T06:15:06.525567Z","shell.execute_reply.started":"2025-06-04T06:15:06.482550Z","shell.execute_reply":"2025-06-04T06:15:06.524697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Missing Values Findings**\n\n\nThe missing values indicate that both the training and test datasets are largely complete, with the train dataset exhibiting 97.23% data completeness and the test dataset showing 93.13% completeness. However, several features have missing values that could impact analytical outcomes if not addressed:\n\n**Train Dataset:**\n\n* `name` is missing in 1 listing (0.01%).\n* `description` is missing in 57 listings (0.81%).\n* `neighborhood_overview` is missing in 1 823 listings (26.04%).\n* All other columns have no missing entries.\n\nSince `neighborhood_overview` is absent for 26.04% of listings and `description` is missing for 0.81% of listings, these text fields will require either imputation (for example, filling with \"No overview provided\") or exclusion. The single missing `name` (0.01%) can be filled with a generic placeholder or removed without materially affecting the dataset.\n\n**Test Dataset:**\n\n* `description` is missing in 31 listings (1.03%).\n* `neighborhood_overview` is missing in 1 424 listings (47.47%).\n* `host_location` is missing in 770 listings (25.67%).\n* `host_about` is missing in 1 441 listings (48.03%).\n* `host_response_time` is missing in 737 listings (24.57%).\n* `host_response_rate` is missing in 737 listings (24.57%).\n* `host_acceptance_rate` is missing in 658 listings (21.93%).\n* `host_is_superhost` is missing in 2 listings (0.07%).\n* `host_neighbourhood` is missing in 2 066 listings (68.87%).\n* `neighbourhood` is missing in 1 424 listings (47.47%).\n* `neighbourhood_cleansed` is missing in 42 listings (1.40%).\n* `property_type` is missing in 39 listings (1.30%).\n* `room_type` is missing in 41 listings (1.37%).\n* `bedrooms` is missing in 60 listings (2.00%).\n* `beds` is missing in 12 listings (0.40%).\n* `minimum_minimum_nights` is missing in 10 listings (0.33%).\n* `maximum_maximum_nights` is missing in 10 listings (0.33%).\n* `availability_365` is missing in 20 listings (0.67%).\n* `first_review` is missing in 263 listings (8.77%).\n* `last_review` is missing in 263 listings (8.77%).\n* `review_scores_rating` is missing in 263 listings (8.77%).\n* `review_scores_accuracy` is missing in 299 listings (9.97%).\n* `review_scores_cleanliness` is missing in 299 listings (9.97%).\n* `review_scores_checkin` is missing in 300 listings (10.00%).\n* `review_scores_communication` is missing in 300 listings (10.00%).\n* `review_scores_location` is missing in 300 listings (10.00%).\n* `review_scores_value` is missing in 300 listings (10.00%).\n* `reviews_per_month` is missing in 263 listings (8.77%).\n\nThese gaps are concentrated in text fields such as `description`, `neighborhood_overview` and `host_about`, host-related attributes such as `host_location`, `host_response_time`, `host_response_rate`, `host_acceptance_rate` and `host_neighbourhood`, and review-related scores. Because many of these features carry important contextual or reputation information, a consistent strategy, such as imputing missing text as \"No data\", filling missing numerical scores with the column median and possibly dropping features with very high missingness, will be necessary.\n\nAddressing these missing values through targeted imputation or, where justified, removal will improve data reliability and ensure that subsequent analyses and models produce accurate, actionable insights.\n","metadata":{}},{"cell_type":"markdown","source":"## **5. Summary Statistics/Visuals**","metadata":{}},{"cell_type":"code","source":"#printing a statistical summary table of the 'Train' Dataset\nprint(\"==================================================================================================================\")\nprint(\"                                     Summary Statistics Table: 'Training Dataset'                                    \") \nprint(\"==================================================================================================================\")\n\ntrain.describe().T #'T' transforms it to a table","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:06.526567Z","iopub.execute_input":"2025-06-04T06:15:06.526905Z","iopub.status.idle":"2025-06-04T06:15:06.628533Z","shell.execute_reply.started":"2025-06-04T06:15:06.526883Z","shell.execute_reply":"2025-06-04T06:15:06.627354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identifying the correlation between variables in 'Train'\nnumerical = train.select_dtypes(include=['number'])\nnumerical_test = test.select_dtypes(include=['number'])\n\n#raw correlation not printed as its visulised below\ncorrelation_train = numerical.corr()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:06.630491Z","iopub.execute_input":"2025-06-04T06:15:06.630896Z","iopub.status.idle":"2025-06-04T06:15:06.665826Z","shell.execute_reply.started":"2025-06-04T06:15:06.630866Z","shell.execute_reply":"2025-06-04T06:15:06.664553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Visulising the current correlation of 'Train' in a heatmap\n\n#Setting the heatmap sizing\nplt.figure(figsize=(20,10))\n\n#Setting a pretty colour map\ncmap = 'viridis'\n\n#adding a title (suptitle used as 'title' overlaps with the heatmap), (x) to center it, (y) to add white space between the title and heatmap\nplt.suptitle(\"Variable Correlations within the 'Training' Dataset\", x=0.43,y=0.94, fontsize=20)\n\n#adding the correlation annotations to 2 decimal places\nsns.heatmap(correlation_train, annot=True,fmt='.2f',cmap=cmap)\n\n#printing the heatmap\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:06.667074Z","iopub.execute_input":"2025-06-04T06:15:06.667834Z","iopub.status.idle":"2025-06-04T06:15:09.414494Z","shell.execute_reply.started":"2025-06-04T06:15:06.667804Z","shell.execute_reply":"2025-06-04T06:15:09.413434Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Key Observations and Insights\n\n\n### Correlation & Univariate Data Characteristics\n\nTo uncover data insights, a heatmap was used to show relationships between different variables in ‘Train’, which assists in visualising their correlation. Additionally, summary statistics were performed to identify key characteristics in the data to determine range, variability and central tendency of the features. Both analyses can assist in decision making by highlighting which listing attributes most influence nightly price and where to focus feature engineering for model development.\n\n*Note: The heatmap shows only continuous, numerical variables prior to any data cleaning, transformation or extraction. This is a limitation when analysing correlations.*\n\n### Strong Positive Correlations\n\n* **Review Scores Rating x Review Scores Accuracy (0.89)**\n  Listings that score highly for overall rating also tend to score highly for accuracy. This suggests that accuracy of the listing description and amenities contributes significantly to guests’ overall satisfaction. For hosts, emphasising accurate photos and amenity details may improve both accuracy and overall rating.\n\n* **Review Scores Rating x Review Scores Value (0.85)**\n  Higher perceived value strongly aligns with a higher overall rating. Guests who feel they receive good value for money tend to rate the listing more favourably. Hosts targeting mid-to-long-stay bookings can focus on value-added services—such as flexible check-in or local guides—to boost both value and overall rating.\n\n* **Availability 30 x Availability 60 (0.89)**\n  Listings that are frequently available in the next 30 nights are also likely to be available over 60 nights. This consistency indicates that availability patterns remain stable over short-term windows. Property managers can use this insight for yield management by adjusting minimum-stay rules or pricing during low-availability periods.\n\n* **Bedrooms x Accommodates (0.86)**\n  Properties with more bedrooms naturally accommodate more guests. This correlation confirms that larger listings should be marketed at a premium per night compared to smaller units, especially for group travellers or families.\n\n### Strong Negative Correlations\n\n* **Reviews per Month x Number of Reviews (–0.35)**\n  A negative correlation exists because ‘number\\_of\\_reviews’ is cumulative while ‘reviews\\_per\\_month’ drops as time passes without new reviews. In practical terms, listings with very high total reviews might have few recent reviews, signalling a need to refresh marketing or update amenities to maintain guest interest.\n\n* **Number of Reviews x Availability 365 (–0.20)**\n  Listings with many reviews tend to be booked more often, resulting in lower overall annual availability. Hosts can track this metric to balance occupancy and allow for necessary maintenance windows.\n\n* **Review Scores Cleaning x Review Scores Check-in (–0.02)**\n  Though weak, a slight inverse relation suggests that very high cleanliness ratings correlate with marginally lower check-in satisfaction, possibly due to hosts prioritising cleaning over streamlined check-in. Understanding this trade-off may help hosts to balance both aspects effectively.\n\n### Weak Price Correlations\n\n* **Price x Bedrooms (0.08)**\n  The small positive relationship indicates that listings with more bedrooms generally cost more per night, but the effect is modest. Pricing strategy should also consider location, property type and guest ratings, not bedrooms alone.\n\n* **Price x Accommodates (0.04)**\n  A very weak positive link shows that the number of guests capacity has some influence on price but is not the primary driver. Hosts with high-capacity properties might need to rely on superior guest experience (ratings) and location to justify a higher nightly rate.\n\n### Univariate Data Characteristics\n\n* **‘Price’** ranges from \\$25 to \\$145 160, with a mean of \\$285.65 and a median of \\$172.00. The wide range indicates both budget-friendly and high-end listings in the market. A right-skewed distribution (mean > median) suggests some very expensive listings pulling the average up.\n\n* **‘Bedrooms’** ranges from 1 to 15, with a mean of 1.79 and a median of 1.00. Most listings have one or two bedrooms (75% have ≤2 bedrooms), indicating that smaller properties dominate the market.\n\n* **‘Accommodates’** spans from 1 to 30 guests, with a mean of 2.56 and a median of 2.00. Over 50% of listings accommodate two guests or fewer, reinforcing the prevalence of smaller, short-stay rentals.\n\n* **‘Number of Reviews’** ranges from 0 to 1 328, with a mean of 28.34 and a median of 10.00. A few listings have very high review counts, while the majority fall below 50 total reviews.\n\n* **‘Review Scores Rating’** spans from 0.00 to 5.00, with a mean of 4.82 and a median of 4.93. Most listings score above 4.50, showing that highly rated properties are the norm.\n\n* **‘Availability 365’** ranges from 0 to 365 days, with a mean of 177.85 and a median of 161.00. Half of all listings are available for 161 days or fewer per year, indicating moderate occupancy levels on average.\n\nBy examining both correlation and univariate characteristics, we can see that guest reviews and availability patterns are critical context for pricing. Hosts and platform managers should prioritise improving guest experiences and managing availability to optimise revenue.\n","metadata":{}},{"cell_type":"code","source":"#printing output heading\nprint(\"===============================================================\")\nprint(\"           Outlier Identification for both Datasets            \") \nprint(\"===============================================================\")\n\n#Identifying the outliers within the 'Train; and 'Test' Dataset using inter-quartile range\ndef find_outliers_IQR(train):\n   q1=numerical.quantile(0.25) #where majority of the data is located \n   q3=numerical.quantile(0.75) #where majority of the data is located\n   IQR=q3-q1\n\n#any data not in the majory range is flagged as an outlier\n   outliers = numerical[((numerical<(q1-1.5*IQR)) | (numerical>(q3+1.5*IQR)))] \n   return outliers\n\noutliers = find_outliers_IQR(numerical)\n\n#7000 is chosen as thats the max of values in 'Train' \n#[0:36] is used to index all the columns\nnum = 7000 - outliers.isnull().sum()[0:36] \n\nprint(\"---------------------------------------------------------------\")\nprint(\"Number of Outliers: Train Data\")\nprint(\"---------------------------------------------------------------\")\nfor column, count in num.items():\n    print(f\"{column}: {count}\")\n    \n#------------------------------------------------------------------------------------------------------------------------------------------    \ndef find_outliers_IQR_test(numerical_test):\n    q1_test = numerical_test.quantile(0.25)\n    q3_test = numerical_test.quantile(0.75)\n    IQR_test=q3_test-q1_test\n\n    outliers_test = numerical_test[((numerical_test<(q1_test-1.5*IQR_test)) | (numerical_test>(q3_test+1.5*IQR_test)))]\n    return outliers_test\n\noutliers_test = find_outliers_IQR_test(numerical_test)\n\n#3000 is chosen as thats the max of values in 'Test'\n#[0:37] is used to index all the columns\nnum_test = 3000 - outliers_test.isnull().sum()[0:37]\n\nprint(\"---------------------------------------------------------------\")\nprint(\"Number of Outliers: Test Data\")\nprint(\"---------------------------------------------------------------\")\nfor column, count in num_test.items():\n    print(f\"{column}: {count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.415501Z","iopub.execute_input":"2025-06-04T06:15:09.415850Z","iopub.status.idle":"2025-06-04T06:15:09.493358Z","shell.execute_reply.started":"2025-06-04T06:15:09.415823Z","shell.execute_reply":"2025-06-04T06:15:09.492505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The datasets reveal significant outliers across multiple variables, notably in:\n\n* **host\\_listings\\_count** (17.81% in the training set and 14.70% in the test set)\n* **latitude** (12.34% in the training set and 10.33% in the test set)\n* **longitude** (17.27% in the training set and 20.83% in the test set)\n* **minimum\\_nights** (12.61% in the training set and 9.87% in the test set)\n\nHigh outlier percentages in these features indicate geographic clustering of extreme values, for example listings located far from central areas, and irregular booking requirements, for example very high or very low minimum-night rules. These issues could skew analysis and reduce model performance.\n\nAdditional variables with notable outlier rates include:\n\n* **bedrooms** (6.30% in the training set and 7.27% in the test set)\n* **beds** (3.14% in the training set and 1.77% in the test set)\n* **number\\_of\\_reviews** (6.54% in the training set and 5.97% in the test set)\n* **review\\_scores\\_communication** (8.64% in the training set and 8.50% in the test set)\n\nThese percentages show that a subset of listings have an unusually high bedroom count, an exceptionally large number of reviews or outlier guest-communication scores, all of which may distort model estimates if not addressed.\n\nEffective handling of these outliers through techniques such as trimming extreme values, applying robust scaling or using transformations is crucial to maintain analytical accuracy and ensure stable model predictions across both datasets. Addressing these outliers will help improve the robustness of insights and enhance predictive accuracy in subsequent analysis.\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Task 2: Data Cleaning, Missing Observations and Feature Engineering\n\n- You must clearly explain all your answers in both the Markdown file and the recorded video. \n\n**Total Marks: 9**","metadata":{}},{"cell_type":"markdown","source":"Student in charge of this task: `(Max Cochrane)`","metadata":{}},{"cell_type":"markdown","source":"**Task 2, Question 1**: Clean **all** numerical features so that they can be used in training algorithms. For instance, `host_response_rate` feature is in object format containing both numerical values and text. Extract numerical values (or equivalently eliminate the text) so that the numerical values can be used as a regular feature.  \n(2 marks)","metadata":{}},{"cell_type":"code","source":"temp_bathrooms_train = train['bathrooms']\ntemp_price_train = train['price']\ntemp_host_response_rate_train = train['host_response_rate']\ntemp_host_acceptance_rate_train = train['host_acceptance_rate']\n\ntemp_bathrooms_test = test['bathrooms']\ntemp_host_response_rate_test = test['host_response_rate']\ntemp_host_acceptance_rate_test = test['host_acceptance_rate']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.494313Z","iopub.execute_input":"2025-06-04T06:15:09.494580Z","iopub.status.idle":"2025-06-04T06:15:09.500414Z","shell.execute_reply.started":"2025-06-04T06:15:09.494554Z","shell.execute_reply":"2025-06-04T06:15:09.499585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Features: (bathrooms, price, host_response_rate and host_acceptance_rate) have been stored in temporary variables so the variables are kept in their original form.","metadata":{}},{"cell_type":"code","source":"#Rounding latitude to 6 decimal places\ntrain['latitude']  = train['latitude'].round(6)\ntest['latitude']   = test['latitude'].round(6)\n\n#Rounding longitude to 6 decimal places\ntrain['longitude'] = train['longitude'].round(6)\ntest['longitude']  = test['longitude'].round(6)\n\n#Rounding bathrooms to 1 decimal place\ntrain['bathrooms'] = train['bathrooms'].round(1)\ntest['bathrooms']  = test['bathrooms'].round(1)\n\n#Rounding review_scores_rating to 1 decimal place\ntrain['review_scores_rating'] = train['review_scores_rating'].round(1)\ntest['review_scores_rating']  = test['review_scores_rating'].round(1)\n\n#Rounding review_scores_accuracy to 1 decimal place\ntrain['review_scores_accuracy'] = train['review_scores_accuracy'].round(1)\ntest['review_scores_accuracy']  = test['review_scores_accuracy'].round(1)\n\n#Rounding review_scores_cleanliness to 1 decimal place\ntrain['review_scores_cleanliness'] = train['review_scores_cleanliness'].round(1)\ntest['review_scores_cleanliness']  = test['review_scores_cleanliness'].round(1)\n\n#Rounding review_scores_checkin to 1 decimal place\ntrain['review_scores_checkin'] = train['review_scores_checkin'].round(1)\ntest['review_scores_checkin']  = test['review_scores_checkin'].round(1)\n\n#Rounding review_scores_communication to 1 decimal place\ntrain['review_scores_communication'] = train['review_scores_communication'].round(1)\ntest['review_scores_communication']  = test['review_scores_communication'].round(1)\n\n#Rounding review_scores_location to 1 decimal place\ntrain['review_scores_location'] = train['review_scores_location'].round(1)\ntest['review_scores_location']  = test['review_scores_location'].round(1)\n\n#Rounding review_scores_value to 1 decimal place\ntrain['review_scores_value'] = train['review_scores_value'].round(1)\ntest['review_scores_value']  = test['review_scores_value'].round(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.501374Z","iopub.execute_input":"2025-06-04T06:15:09.501656Z","iopub.status.idle":"2025-06-04T06:15:09.529406Z","shell.execute_reply.started":"2025-06-04T06:15:09.501608Z","shell.execute_reply":"2025-06-04T06:15:09.528393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"---------------------------------------------------------------\")\nprint(\"After Rounding: Training Data\")\nprint(\"---------------------------------------------------------------\")\nprint(train[['latitude','longitude','bathrooms',\n             'review_scores_rating','review_scores_accuracy',\n             'review_scores_cleanliness','review_scores_checkin',\n             'review_scores_communication','review_scores_location',\n             'review_scores_value']].head())\nprint(\"---------------------------------------------------------------\")\nprint(\"After Rounding: Test Data\")\nprint(\"---------------------------------------------------------------\")\nprint(test[['latitude','longitude','bathrooms',\n            'review_scores_rating','review_scores_accuracy',\n            'review_scores_cleanliness','review_scores_checkin',\n            'review_scores_communication','review_scores_location',\n            'review_scores_value']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.530469Z","iopub.execute_input":"2025-06-04T06:15:09.530796Z","iopub.status.idle":"2025-06-04T06:15:09.555246Z","shell.execute_reply.started":"2025-06-04T06:15:09.530774Z","shell.execute_reply":"2025-06-04T06:15:09.554451Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Features rounded to one decimal place for consistency:**\nseller_rating, bathrooms, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_score_checkin, review_scores_communication, review_scores_location, review_scores_value.\n\nThese were all rounded to one decimal place to keep their formats the same.\n\n**Latitude and longitude rounding:**\nLatitude and longitude were rounded to six decimal places. Ten decimal places was overly precise while Six decimals align with six-figure military grid references, ensuring accurate location without being too complex.\n","metadata":{}},{"cell_type":"markdown","source":"### **Extracting Numeric Values in Training and Testing data Sets**","metadata":{}},{"cell_type":"code","source":"#Cleaning Training Data\ntrain['bathrooms'] = pd.to_numeric(train['bathrooms'].astype(str).str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')\ntrain['host_response_rate'] = pd.to_numeric(train['host_response_rate'].astype(str).str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')\ntrain['host_acceptance_rate'] = pd.to_numeric(train['host_acceptance_rate'].astype(str).str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')\ntrain['price'] = pd.to_numeric(train['price'].astype(str).str.replace(r'[\\$,]', '', regex=True).str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')\n#Cleaning Testing Data\ntest['bathrooms'] = pd.to_numeric(test['bathrooms'].astype(str).str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')\ntest['host_response_rate'] = pd.to_numeric(test['host_response_rate'].astype(str).str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')\ntest['host_acceptance_rate'] = pd.to_numeric(test['host_acceptance_rate'].astype(str).str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.556240Z","iopub.execute_input":"2025-06-04T06:15:09.556601Z","iopub.status.idle":"2025-06-04T06:15:09.614040Z","shell.execute_reply.started":"2025-06-04T06:15:09.556580Z","shell.execute_reply":"2025-06-04T06:15:09.612820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify cleaning\nprint(\"---------------------------------------------------------------\")\nprint(\"After Cleaning: Training Data\")\nprint(\"---------------------------------------------------------------\")\nprint(train[['bathrooms','host_response_rate','host_acceptance_rate','price']].head())\n\nprint(\"---------------------------------------------------------------\")\nprint(\"After Cleaning: Test Data\")\nprint(\"---------------------------------------------------------------\")\nprint(test[['bathrooms','host_response_rate','host_acceptance_rate']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.615028Z","iopub.execute_input":"2025-06-04T06:15:09.615298Z","iopub.status.idle":"2025-06-04T06:15:09.641202Z","shell.execute_reply.started":"2025-06-04T06:15:09.615277Z","shell.execute_reply":"2025-06-04T06:15:09.640235Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Turn the column into text, then grab just the numbers (and any decimal), and finally convert that text of numbers into a numeric type. Example: For “price” we also remove “\\$” and commas before pulling out the digits. This cleans the data to make it workable.\n","metadata":{}},{"cell_type":"markdown","source":"**Task 2, Question 2** Create at least 4 new features from existing features which contain multiple items of information.   \n(2 marks)","metadata":{}},{"cell_type":"code","source":"# Get today's date\ncurrent = datetime.date.today()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.642224Z","iopub.execute_input":"2025-06-04T06:15:09.642485Z","iopub.status.idle":"2025-06-04T06:15:09.650893Z","shell.execute_reply.started":"2025-06-04T06:15:09.642466Z","shell.execute_reply":"2025-06-04T06:15:09.649958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Getting Current Date for Days since last Review and Time as a Host","metadata":{}},{"cell_type":"code","source":"# Creating a new variable called Amenities Count\ntrain['amenities_count'] = train['amenities'].str.count(',') + 1\ntest['amenities_count']  = test['amenities'].str.count(',') + 1\n\n# Creating a new variable called Host Tenure in Days\ntrain['Time_as_a_Host'] = (pd.to_datetime(current) - pd.to_datetime(train['host_since'])).dt.days\ntest['Time_as_a_Host']  = (pd.to_datetime(current) - pd.to_datetime(test['host_since'])).dt.days\n\n# Creating a new variable called Availability Ratio\ntrain['availability_ratio'] = train['availability_365'] / 365\ntest['availability_ratio']  = test['availability_365'] / 365\n\n# Creating a new variable called Days Since Last Review\ntrain['days_since_last_review'] = (pd.to_datetime(current) - pd.to_datetime(train['last_review'])).dt.days\ntest['days_since_last_review']  = (pd.to_datetime(current) - pd.to_datetime(test['last_review'])).dt.days\n\n# Creating a new variable called Superhost Flag\ntrain['superhost_flag'] = (train['host_is_superhost'] == 't').astype(int)\ntest['superhost_flag']  = (test['host_is_superhost'] == 't').astype(int)\n\n# Creating a new variable called Neighbourhood Review Density\ntrain['neighbourhood_review_density'] = train['number_of_reviews'] / train['availability_365']\ntest['neighbourhood_review_density']  = test['number_of_reviews'] / test['availability_365']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.653834Z","iopub.execute_input":"2025-06-04T06:15:09.654078Z","iopub.status.idle":"2025-06-04T06:15:09.736632Z","shell.execute_reply.started":"2025-06-04T06:15:09.654061Z","shell.execute_reply":"2025-06-04T06:15:09.735879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify new features exist\nnew_features = ['amenities_count','Time_as_a_Host','availability_ratio','days_since_last_review','superhost_flag','neighbourhood_review_density']\n\nprint(\"---------------------------------------------------------------\")\nprint(\"Checking new features: Training Data\")\nprint(\"---------------------------------------------------------------\")\nprint(train[new_features].head())\n\nprint(\"---------------------------------------------------------------\")\nprint(\"Checking new features: Testing Data\")\nprint(\"---------------------------------------------------------------\")\nprint(test[new_features].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.737735Z","iopub.execute_input":"2025-06-04T06:15:09.738018Z","iopub.status.idle":"2025-06-04T06:15:09.751638Z","shell.execute_reply.started":"2025-06-04T06:15:09.737999Z","shell.execute_reply":"2025-06-04T06:15:09.750688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **New Variables**\n\n1) amenities_count\n\nSource data: Derived from the amenities column, which lists all amenities as a comma-separated string (for example “Wifi,Kitchen,Air conditioning,Heating”).\n\nHow it’s made: We count how many commas appear in the amenities text and add one. For instance, three commas means four amenities. This gives us a single integer showing how many extras the host provides, since more amenities often relate to a higher nightly rate.\n\n2) host_tenure_days\n\nSource data: Based on the host_since column, which records the date the host joined Airbnb.\n\nHow it’s made: We calculate today’s date (current = datetime.date.today()), convert the host’s join date to a pandas datetime, then subtract the join date from today. The result is the total number of days the host has been active. Hosts who have been around longer often charge more because they have built experience and trust.\n\n3) availability_ratio\n\nSource data: Taken from availability_365, the number of days the listing is available over the next year.\n\nHow it’s made: We divide the “days available” value by 365 to get a number between 0 and 1. A low ratio, close to 0, means the place is booked most of the year, indicating high demand and justifying a higher price. A high ratio, close to 1, means the listing is open nearly every day, suggesting lower demand.\n\n4) days_since_last_review\n\nSource data: Based on the last_review column, which shows the date of the most recent guest review.\n\nHow it’s made: We subtract the date of the last review from today’s date (current = datetime.date.today()), after converting both to pandas datetime. The result is how many days have passed since someone last reviewed the listing. Listings with very recent reviews tend to be more active, which can support a premium rate.\n\n5) superhost_flag\n\nSource data: Taken from host_is_superhost, which indicates whether the host is a Superhost (“t” for true or “f” for false).\n\nHow it’s made: We check if host_is_superhost equals “t” and convert that to 1; otherwise we use 0. A value of 1 shows the host is a Superhost, a status that often allows them to charge more because guests trust them more.\n\n6) neighbourhood_review_density\n\nSource data: Combines number_of_reviews (total reviews) with availability_365 (days the listing is available in a year).\n\nHow it’s made: We divide total reviews by the number of available days. This tells us how many reviews the listing receives on average for each day it is open. A higher density indicates popularity, which usually corresponds to a higher price.\n\nSix features give the model more validity by adding host reputation and listing popularity, making price predictions more accurate. Four features may not caputre as many features and may have a less accurate prediction","metadata":{}},{"cell_type":"markdown","source":"**Task 2, Question 3**: Impute the missing values for all features in both the training and test datasets.   \n(2 marks)","metadata":{}},{"cell_type":"code","source":"# Numeric features with missing values\nnum_train_missing = ['bedrooms','beds','minimum_minimum_nights','maximum_maximum_nights','availability_365','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value','bathrooms','host_response_rate','host_acceptance_rate']\n\n# replaces with train medians\nmedian_values = train[num_train_missing].median()\ntrain[num_train_missing] = train[num_train_missing].fillna(median_values)\ntest[num_train_missing]  = test[num_train_missing].fillna(median_values)\n\n# Numeric features in test not in train\nextra_num_test_missing = ['review_scores_rating', 'reviews_per_month']\nextra_medians = train[extra_num_test_missing].median()\ntrain[extra_num_test_missing] = train[extra_num_test_missing].fillna(extra_medians)\ntest[extra_num_test_missing]  = test[extra_num_test_missing].fillna(extra_medians)\n\n# Date features to be treat as categorical\ndate_cols = ['first_review', 'last_review']\nfor col in date_cols:\n    mode_val = train[col].mode().iloc[0]\n    train[col] = train[col].fillna(mode_val)\n    test[col]  = test[col].fillna(mode_val)\n\n# Categorical features with missing values\ncat_train_missing = ['name','description','neighborhood_overview','host_location','host_about','host_neighbourhood','neighbourhood','neighbourhood_cleansed','property_type','room_type','host_is_superhost','host_response_time']\n\nmode_values = train[cat_train_missing].mode().iloc[0]\ntrain[cat_train_missing] = train[cat_train_missing].fillna(mode_values)\ntest[cat_train_missing]  = test[cat_train_missing].fillna(mode_values)\n\n# Fix new variables\n\ntrain['availability_ratio'] = train['availability_365'] / 365\ntest['availability_ratio']  = test['availability_365']  / 365\n\ntrain['neighbourhood_review_density'] = train.apply(lambda r: r['number_of_reviews'] / r['availability_365'] if r['availability_365'] != 0 else 0, axis=1)\ntest['neighbourhood_review_density']  = test.apply(lambda r: r['number_of_reviews'] / r['availability_365'] if r['availability_365'] != 0 else 0, axis=1)\n\ncurrent = datetime.date.today()\ntrain['days_since_last_review'] = (pd.to_datetime(current) - pd.to_datetime(train['last_review'])).dt.days\ntest['days_since_last_review']  = ( pd.to_datetime(current) - pd.to_datetime(test['last_review'])).dt.days","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.752578Z","iopub.execute_input":"2025-06-04T06:15:09.753038Z","iopub.status.idle":"2025-06-04T06:15:09.966814Z","shell.execute_reply.started":"2025-06-04T06:15:09.753009Z","shell.execute_reply":"2025-06-04T06:15:09.965948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify no values are missing anymore\nprint(\"---------------------------------------------------------------\")\nprint(\"missing values after cleaning: Training Data\")\nprint(\"---------------------------------------------------------------\")\nprint(train.isnull().sum()[train.isnull().sum() > 0])\n\nprint(\"---------------------------------------------------------------\")\nprint(\"missing values after cleaning: Testing Data\")\nprint(\"---------------------------------------------------------------\")\nprint(test.isnull().sum()[test.isnull().sum() > 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:09.967394Z","iopub.execute_input":"2025-06-04T06:15:09.967660Z","iopub.status.idle":"2025-06-04T06:15:10.015529Z","shell.execute_reply.started":"2025-06-04T06:15:09.967635Z","shell.execute_reply":"2025-06-04T06:15:10.014658Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Task 2, Question 4**: Encode all categorical variables appropriately as discussed in class. \n\n- Where multiple values are given for an observation encode the observation as 'other'. \n- Where a categorical feature contains more than 5 unique values, map the features into 5 most frequent values + 'other' and then encode appropriately.  \n(2 marks)","metadata":{}},{"cell_type":"code","source":"# Create a subset of categorical columns from the training data\ncat_train = train[[ 'source',\n    'host_response_time',\n    'host_is_superhost',\n    'host_neighbourhood',\n    'host_verifications',\n    'host_has_profile_pic',\n    'host_identity_verified',\n    'neighbourhood',\n    'neighbourhood_cleansed',\n    'property_type',\n    'room_type',\n    'has_availability',\n    'instant_bookable'\n]].astype(str)\n\n\n\nfor col in cat_train.columns:\n    # If the column has more than 5 unique values:\n    if cat_train[col].nunique() > 5:\n        value_counts_train = cat_train[col].value_counts()\n        # Calculate value counts and get the top 5 most frequent values\n        top_5_val_train = value_counts_train.head(5).index.tolist()\n        # Replace values not in the top 5 with 'Other'\n        cat_train[col] = cat_train[col].apply(lambda x: x if x in top_5_val_train else 'Other')\n\n# Update the categorical columns in the original training DataFrame\ntrain[cat_train.columns] = cat_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.016432Z","iopub.execute_input":"2025-06-04T06:15:10.016703Z","iopub.status.idle":"2025-06-04T06:15:10.047291Z","shell.execute_reply.started":"2025-06-04T06:15:10.016684Z","shell.execute_reply":"2025-06-04T06:15:10.046603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Do the same as above for test data set\ncat_test = test[[ 'source',\n    'host_response_time',\n    'host_is_superhost',\n    'host_neighbourhood',\n    'host_verifications',\n    'host_has_profile_pic',\n    'host_identity_verified',\n    'neighbourhood',\n    'neighbourhood_cleansed',\n    'property_type',\n    'room_type',\n    'has_availability',\n    'instant_bookable'\n]].astype(str)\n\nfor col in cat_test.columns:\n    if cat_test[col].nunique() > 5:\n        value_counts_test = cat_test[col].value_counts()\n\n        top_5_val_test = value_counts_test.head(5).index.tolist()\n\n        cat_test[col] = cat_test[col].apply(lambda x: x if x in top_5_val_test else 'Other')\n\ntest[cat_test.columns] = cat_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.048110Z","iopub.execute_input":"2025-06-04T06:15:10.048390Z","iopub.status.idle":"2025-06-04T06:15:10.069443Z","shell.execute_reply.started":"2025-06-04T06:15:10.048365Z","shell.execute_reply":"2025-06-04T06:15:10.068426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initiate LabelEncoder\nlabel = LabelEncoder()\n\n# Iterate through each column\nfor col in cat_train.columns:\n  # Encodes all values in each categorical column\n    train[col] = label.fit_transform(train[col])\n\nfor col in cat_test.columns:\n    test[col] = label.fit_transform(test[col])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.070509Z","iopub.execute_input":"2025-06-04T06:15:10.070862Z","iopub.status.idle":"2025-06-04T06:15:10.105596Z","shell.execute_reply.started":"2025-06-04T06:15:10.070837Z","shell.execute_reply":"2025-06-04T06:15:10.104762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify that train and test categorical columns are now integers\nprint(\"=== Train dtypes for cleaned categories ===\")\nprint(train[cat_cols].dtypes)\n\nprint(\"\\n=== Test dtypes for cleaned categories ===\")\nprint(test[cat_cols].dtypes)\n\nprint(\"\\n=== Unique values in train (per column) ===\")\nfor col in cat_cols:\n    print(f\"{col}: {sorted(train[col].unique())}\")\n\nprint(\"\\n=== Unique values in test (per column) ===\")\nfor col in cat_cols:\n    print(f\"{col}: {sorted(test[col].unique())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.106566Z","iopub.execute_input":"2025-06-04T06:15:10.106892Z","iopub.status.idle":"2025-06-04T06:15:10.135230Z","shell.execute_reply.started":"2025-06-04T06:15:10.106867Z","shell.execute_reply":"2025-06-04T06:15:10.134247Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In question 4 we identified all categorical fields in both the training and testing data. For each field with more than five unique categories, we retained the five most frequent values and recoded all other entries as “Other.” Finally, we applied a label encoder to each cleaned categorical column so that every category is represented numerically.","metadata":{}},{"cell_type":"markdown","source":"**Task 2, Question 5**: Perform any additional data preparation steps you consider necessary before building your predictive models, and clearly explain each action you take.  \n(1 mark)","metadata":{}},{"cell_type":"code","source":"train.drop(['ID'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.135924Z","iopub.status.idle":"2025-06-04T06:15:10.136248Z","shell.execute_reply.started":"2025-06-04T06:15:10.136073Z","shell.execute_reply":"2025-06-04T06:15:10.136088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.drop(['ID'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.138069Z","iopub.status.idle":"2025-06-04T06:15:10.138426Z","shell.execute_reply.started":"2025-06-04T06:15:10.138251Z","shell.execute_reply":"2025-06-04T06:15:10.138267Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Prior to Task 3, I verified that all variables were properly encoded. I removed the ID column because, as a unique identifier, it offers no value for model training. The ID will be retained solely for inclusion in the submission file once test set predictions are made.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Task 3: Fit and tune predictive models, submit predictions & win competition\n\n- You must clearly explain all your answers in both the Markdown file and the recorded video.\n- \n**Total Marks: 9**\n\nFor this task, you should not create any new features and must rely on the variables constructed in Task 2.  \n \n\n1. Perform some EDA to measure the relationship between the features and the target variable, and carefully explain your findings. (2 marks)\n\n2. Choose and carefully explain 3 different machine learning (ML) regression models that you will apply in this competition. (2 marks)\n   \n3. Train the models from the above question and tune their hyperparameters via cross-validation. Discuss the fitted weights, optimised hyperparameter values, and their training dataset predictive performance. (2 marks)   \n\n4. Select your best model, create predictions of the test dataset and submit your forecasts on Kaggle's competition page. Provide Kaggle ranking and score (screenshots) and comment on your performance in the competition. (2 marks)\n\n5. Suggest ways to improve your ranking and implement them, providing further evidence from Kaggle (screenshots). (1 mark)   \n\n- Hints:\n    - Make sure your Python code works so that your results can be replicated by the marker\n    - You will receive the mark of zero for this Task if your code does not produce the forecasts uploaded to Kaggle\n\n","metadata":{}},{"cell_type":"markdown","source":"Student in charge of this task: `(Shambhav Shrestha)`","metadata":{}},{"cell_type":"markdown","source":"### **Exploratory Data Analysis**","metadata":{}},{"cell_type":"code","source":"# 1. Explicitly list every true numeric column (after cleaning and feature creation):\nnumeric_cols = [\n    'accommodates',\n    'bedrooms',\n    'beds',\n    'bathrooms',\n    'latitude',\n    'longitude',\n    'availability_365',\n    'number_of_reviews',\n    'reviews_per_month',\n    'review_scores_rating',\n    'review_scores_accuracy',\n    'review_scores_cleanliness',\n    'review_scores_checkin',\n    'review_scores_communication',\n    'review_scores_location',\n    'review_scores_value',\n    'host_response_rate',\n    'host_acceptance_rate',\n    'amenities_count',               \n    'Time_as_a_Host',                \n    'availability_ratio',            \n    'days_since_last_review',        \n    'superhost_flag',                \n    'neighbourhood_review_density',\n    'source',\n    'host_response_time',\n    'host_is_superhost',\n    'host_neighbourhood',\n    'host_verifications',\n    'host_has_profile_pic',\n    'host_identity_verified',\n    'neighbourhood',\n    'neighbourhood_cleansed',\n    'property_type',\n    'room_type',\n    'has_availability',\n    'instant_bookable'\n]\n\n# 2. Make sure 'price' is numeric\ntrain['price'] = pd.to_numeric(train['price'], errors='coerce')\n\n# 3. Subset train to only those numeric columns + 'price'\ndf_numeric = train[numeric_cols + ['price']].copy()\n\n# 5. Compute Pearson correlation of each numeric feature with price\ncorr_with_price = df_numeric.corr()['price'].sort_values(ascending=False)\n\nprint(\"\\nCorrelation of every numeric feature with price:\")\nprint(corr_with_price)\n\n# 6. Highlight features where |corr| > 0.25 (excluding 'price')\nsignificant = corr_with_price.loc[\n    (corr_with_price.abs() > 0.25) & (corr_with_price.index != 'price')\n]\nprint(\"\\nFeatures with |correlation| > 0.25 against price:\")\nprint(significant)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.139836Z","iopub.status.idle":"2025-06-04T06:15:10.140202Z","shell.execute_reply.started":"2025-06-04T06:15:10.140029Z","shell.execute_reply":"2025-06-04T06:15:10.140045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To determine which variables most affect price, we run a list of correlations with price. In this dataset, accommodates shows the strongest positive correlation with price (0.0356), while property_type has the strongest negative correlation (–0.0285).","metadata":{}},{"cell_type":"code","source":"# Create the figure and GridSpec layout\nfig = plt.figure(figsize=(20, 20))\ngs  = fig.add_gridspec(3, 4, height_ratios=[1, 1, 2])\nfig.suptitle(\"Exploratory Data Analysis on Key Airbnb Variables\", y=0.96, fontsize=18)\n\n\n# Top row: Price Distribution by Room Type (zoomed to $0–$1 000 AUD)\nax1 = fig.add_subplot(gs[0, :])\nsns.boxplot(\n    x='room_type',\n    y='price',\n    data=train,\n    whis=1.5,\n    showfliers=False,\n    palette=\"pastel\",\n    ax=ax1\n)\nax1.set_ylim(0, 1000)\nax1.set_title(\"Price Distribution by Room Type (0–\\$1 000 AUD)\", fontsize=14)\nax1.set_xlabel(\"Room Type\", fontsize=12)\nax1.set_ylabel(\"Price (AUD)\", fontsize=12)\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n\n# Second row, col 1: Zoomed‐in histogram of Price (0–$1000 AUD)\nplt.figure(figsize=(8, 5))\n\nsns.histplot(\n    train['price'], \n    bins=10000, \n    color='steelblue', \n    kde=False\n)\nplt.xlim(0, 1000)\n\n# 3) Label everything clearly\nplt.title(\"Zoomed Distribution of Price (0–$1 000 AUD)\", fontsize=14)\nplt.xlabel(\"Price (AUD)\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n# Second row, col 2: Review Scores Rating vs Price (limit Y to 0–$1 000 AUD)\nax3 = fig.add_subplot(gs[1, 1])\nsns.scatterplot(\n    x='review_scores_rating',\n    y='price',\n    data=train,\n    ax=ax3,\n    color=\"skyblue\",\n    alpha=0.5\n)\nsns.regplot(\n    x='review_scores_rating',\n    y='price',\n    data=train,\n    ax=ax3,\n    scatter=False,\n    color=\"navy\",\n    line_kws={'linewidth': 2}\n)\nax3.set_ylim(0, 1000)\nax3.set_title(\"Review Scores Rating vs Price (0–\\$1 000 AUD)\", fontsize=14)\nax3.set_xlabel(\"Review Scores Rating\", fontsize=12)\nax3.set_ylabel(\"Price (AUD)\", fontsize=12)\n\n# Second row, col 3: Availability Ratio vs Price (limit Y to 0–$1 000 AUD)\nax4 = fig.add_subplot(gs[1, 2])\nsns.scatterplot(\n    x='availability_ratio',\n    y='price',\n    data=train,\n    ax=ax4,\n    color=\"lightcoral\",\n    alpha=0.5\n)\nsns.regplot(\n    x='availability_ratio',\n    y='price',\n    data=train,\n    ax=ax4,\n    scatter=False,\n    color=\"maroon\",\n    line_kws={'linewidth': 2}\n)\nax4.set_ylim(0, 1000)\nax4.set_title(\"Availability Ratio vs Price (0–\\$1 000 AUD)\", fontsize=14)\nax4.set_xlabel(\"Availability Ratio\", fontsize=12)\nax4.set_ylabel(\"Price (AUD)\", fontsize=12)\n\n# Second row, col 4: Amenities Count vs Price (limit Y to 0–$1 000 AUD)\nax5 = fig.add_subplot(gs[1, 3])\nsns.scatterplot(\n    x='amenities_count',\n    y='price',\n    data=train,\n    ax=ax5,\n    color=\"mediumseagreen\",\n    alpha=0.5\n)\nsns.regplot(\n    x='amenities_count',\n    y='price',\n    data=train,\n    ax=ax5,\n    scatter=False,\n    color=\"darkgreen\",\n    line_kws={'linewidth': 2}\n)\nax5.set_ylim(0, 1000)\nax5.set_title(\"Amenities Count vs Price (0–\\$1 000 AUD)\", fontsize=14)\nax5.set_xlabel(\"Amenities Count\", fontsize=12)\nax5.set_ylabel(\"Price (AUD)\", fontsize=12)\n\n# Bottom row: Pairplot for a filtered subset (price ≤ $1 000 AUD)\npairplot_vars = [\n    'price',\n    'review_scores_rating',\n    'availability_ratio',\n    'amenities_count',\n    'bathrooms'\n]\n\nfiltered_data = train[\n    (train['price'] <= 1000) &\n    (train['review_scores_rating'] <= 5) &\n    (train['availability_ratio'] <= 1) &\n    (train['amenities_count'] <= 100) &\n    (train['bathrooms'] <= 5)\n]\n\npairplot = sns.pairplot(\n    filtered_data[pairplot_vars],\n    diag_kind=\"hist\",\n    kind='reg',\n    plot_kws={\"scatter_kws\": {\"alpha\": 0.5}, \"line_kws\": {\"color\": \"purple\", \"linewidth\": 1.5}}\n)\npairplot.fig.suptitle(\"Pairplot of Key Numeric Variables (Price ≤ \\$1 000 AUD)\", y=1.02, fontsize=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:15:10.141343Z","iopub.status.idle":"2025-06-04T06:15:10.141638Z","shell.execute_reply.started":"2025-06-04T06:15:10.141481Z","shell.execute_reply":"2025-06-04T06:15:10.141492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Machine Learning Regression Models**\n- GradientBoostRegressor\n- Lasso Regression\n- SVR Regression","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n---\n## Marking Criteria\n\nTo receive full marks your solutions must satisfy the following criteria:\n\n- Problem Description: 9 marks\n- Data Cleaning: 9 marks\n- Building Forecasting models: 9 marks\n- Video Presentation: 3 marks\n    - Duration less than 15 min, presentation skill and content \n    - Each team member delivers a 5-minute presentation on their assigned task\n    - All assignment questions must be discussed on video  \n    - Your code must be readable on the video\n    - Discuss both the actions you took and, more importantly, the reasoning behind these actions, explaining the significance of key steps\n    - During the video recording, make sure that both your face and Jupyter Notebook are clearly visible\n- Forecasts correctly uploaded to Kaggle\n- Python code is clean and concise\n- Written explanations are provided in clear and easy to understand sentences\n- The assignment notebook is well-organised and easy to follow\n- Failure to meet the above marking criteria will result in a deduction of marks\n\n---\n---","metadata":{}}]}